---
title: 'Laboratorio 1.1: Exploración y visualización de Datos'
date: "Marzo 2022"
author: 'Camila Henriquez Beltran, Pablo Yañez'
output:
  html_document:
    theme: default
    toc: no
  pdf_document:
    toc: no
---

# Declaración de compromiso ético

Nosotros **Camila Henriquez Beltran, Pablo Yañez** , declaramos que realizamos de manera grupal los pasos de la presente actividad. También declaramos no incurrir en copia, ni compartir nuestras respuestas con otras personas ni con otros grupos. Por lo que, ratificamos que las respuestas son de nuestra propia confección y reflejan nuestro propio conocimiento.

# Instrucciones

1.  Trabajen en equipos de dos personas. Salvo excepciones, no se corregirá entregas con menos de dos integrantes.

2.  Modifique este archivo `.Rmd` agregando sus respuestas donde corresponda.

3.  Para cada pregunta, cuando corresponda, **incluya el código fuente que utilizó para llegar a su respuesta**.

4.  El formato de entrega para esta actividad es un archivo html. **Genere un archivo HTML usando RStudio** y súbalo a U-Cursos.

Basta con que uno de los integrantes haga la entrega. Si ambos hacen una entrega en U-Cursos, se revisará cualquiera de éstas.

# Laboratorio

La primera parte de esta actividad son preguntas teóricas que avanzaron en las clases del curso de Minería de datos.

## Teoría

*1. ¿Cuál es el objetivo de la Minería de datos y qué la diferencia de Machine Learning? De un ejemplo para explicar la diferencia.*

**Respuesta: La minería de datos tiene el objetivo de ayudarnos a entender nuestros datos y darles sentido, como por ejemplo el clustering que nos permite extraer patrones de agrupación de los datos, mientras que el Machine Learning se enfoca en resolver una tarea más específica, por ejemplo clasificar imagenes de perros y gatos. En este caso el Data Mining nos podría haber servido para identificar que existen dos clases en nuestro conjunto (perros y gatos) y el machine learning para hacer inferencia sobre datos nuevos.**

*2. Explique qué son los métodos predictivos y descriptivos en minería de datos. De un ejemplo de técnicas en cada uno de los métodos y explique su utilidad*

**Respuesta: Los métodos predictivos se centran en la inferencia a partir de los datos usados como entrenamiento, mientras que los métodos descriptivos intentan 
descubrir patrones antes no vistos para ser usados en otras tareas, un ejemplo de método predictivo es la regresión que nos permite predecir el valor de una variable que depende de otras (lineal o no linealmente), por ejemplo una serie de tiempo (°Temperatura). Por otro lado, un ejemplo de método descriptivo sería una regla de asosiación entre productos de un e-commerce para hacer recomendaciones personalizadas.**

*3. ¿Qué es el análisis exploratorio de datos o EDA?*

**Respuesta: EDA corresponde a la primera aproximacion que se tiene con el dataset. En este analisis exploratorio de los datos se pueden calculan distintos estadisticos y crear graficos, de forma que la info que no se puede ver a simple vista si vemos solo la tabla con datos contenida en el data set pueda ser interpretada mas facilmente. En este analisis se puede calcular la media, desviacion estandr, ver con que tipo de datos se esta trabajando, si tienen alguna distribucion especifica, etc.**

*4. Explique cómo se identifican los valores atípicos u outliers en un boxplot y cuál es su utilidad.*

**Respuesta: El diagrama de caja tiene demarcados los cuartiles de la muestra. Los outliers estan representados fuera del rango de este boxplot (es decir, las pestañas que salen de las cajas). El boxplot muestra la mediana y los cuartiles, al representar estos intervalos es posible visualizar rapidamente como estan distribuidos los datos, donde se concentran estos (el rango inter cuartilico) y ver cuales datos estan alejados de estas concentraciones (los outliers).**

## Práctica

En esta parte de la actividad se trabajará con los datos del Proceso Constituyente 2016-2017 publicados en el Portal de Datos Abiertos del Gobierno de Chile, para mayor información pueden ingresar al siguiente link: <https://datos.gob.cl/dataset/proceso-constituyente-abierto-a-la-ciudadania>. Los datos corresponden a las actas de los Encuentros Locales Autoconvocados (ELAs), en cada cual, un grupo de personas se reune a discutir distintos conceptos como por ejemplo: salud, educación, seguridad, etc.

Los datos con los que trabajarán consisten en la cantidad de veces que cada concepto constitucional fue mencionado por cada localidad de Chile.

Para cargar los datos, use:

```{r}
data_tf <- read.csv("http://dcc.uchile.cl/~hsarmien/mineria/datasets/actas.txt", header = T)
```

**Por cada pregunta adjunte el código R que utilizó para llegar a la respuesta. Respuestas sin código no recibirán puntaje**

### Exploración básica

1.  ¿Cuáles son las dimensiones del dataset (filas, columnas)? Adjunte código o indique cómo determinó la cantidad de datos total. **Respuesta: Hay multiples formas de ver las dimensiones del dataset; Una vez cargada la variable data_tf es posible verla en la ventana de RStudio donde se muestran las variables cargadas, en este caso es posible ver que el dataaset tiene 328 obs y 113 varibales, lo que corresponde a 328 filas y 113 columnas. Otra forma es ocupar las funciones dim o nrow y ncol como se ve en el cuadro de abajo:**

```{r}
# RESPUESTA
dim(data_tf)
nrow(data_tf)
ncol(data_tf)
```

2.  ¿Qué describe cada línea del dataset? (ejemplifique tomando la fila 45)

```{r}
# RESPUESTA
#fila 45
data_tf[45,]

```

**Respuesta: Cada linea en el dataset representa la frecuencia con que cada concepto constitucional (columnas) fue mencionado en la localidad indicada. Así, tomando como ejemplo la fila 45 del dataset tenemos que el concepto 'a huelga' fue mencionado una vez, 'a la educacion' 2 veces, etc.**

3.  ¿Existen localidades repetidas en el dataset? Adjunte el código o indique cómo llegó a esa conclusión.

**Respuesta: Tenemos la funcion implementada 'unique' que cuenta los valores unicos de la columna que le entregamos. Con esto, basta con que el numero de filas del dataset con el numero de valores unicos por localidades sean iguales para concluir que no hay localidades repetidas en el dataset, tal como se muestra en el cuadro de abajo.**

```{r}
# RESPUESTA
length(unique(data_tf$localidad))
nrow(data_tf)

```

### Análisis

1.  Liste todas las localidades donde se discutió el concepto `patriotismo`.

```{r}
library(tidyverse)
# RESPUESTA
patriotismo_df <- data_tf %>% filter(patriotismo > 0)  #se menciona 1 o mas veces patriotismo
patriotismo_df$localidad

```

2.  Liste las 10 localidades que más mencionaron el concepto plurinacionalismo.

```{r}
# RESPUESTA
pluri_df <- data_tf[order(data_tf$plurinacionalismo, decreasing=TRUE),]
pluri_df[1:10, c('localidad','plurinacionalismo')]
```

3.  Liste los 10 conceptos más mencionados a lo largo de todo el proceso.

```{r}
# RESPUESTA
totales <- colSums(data_tf[,2:113])
temas <- colnames(data_tf)[2:113]

d <- data.frame( tema = temas,
                 total = totales)
conceptos_df <- d[order(d$total, decreasing=TRUE),]
conceptos_df[1:10, c('tema', 'total')]
```

4.  Liste las 10 localidades que más participaron en el proceso. Describa cómo definió su medida de participación.

**Respuesta: Definimos un indice de participacion, que corresponde al producto entre la suma de frecuencia de los temas y el numero de temas distintos que se discutieron normalizados.**

```{r}
# RESPUESTA patriotismo_df <- data_tf %>% filter(patriotismo > 0)
sumafila <- rowSums(data_tf[,2:113])
distcero <- rowSums(data_tf[,2:113]!=0)

sumafila <- sumafila/max(sumafila)
distcero <- distcero/max(distcero)

participacion_df <- data.frame(localidad = data_tf$localidad, nvotos = sumafila, temasdistintos=distcero, indiceparti = sumafila*distcero)

participacion_df <- participacion_df[order(participacion_df$indiceparti, decreasing=TRUE),]
participacion_df[1:10, c('localidad', 'indiceparti')]

```

5.  Ejecute el siguiente código que permitirá agregar una nueva columna a nuestro dataframe que solo tendrá el nombre de la región.

```{r, message = F, warning=F}
library(dplyr)
regiones <- strsplit(as.character(data_tf[,1]), '/')
data_tf$region <- sapply(regiones, "[[", 1)
data_tf <- data_tf %>% select(localidad, region, everything())
```

Luego, genere un gráfico de barras (ggplot) que muestre los 10 conceptos más mencionados en cada una de las regiones mencionadas (adjunte gráficos y código). Los conceptos deben mostrarse ordenados descendentemente.

-   `Coquimbo`
-   `Antofagasta`
-   `Metropolitana de Santiago`

Cabe resaltar, que se esperan tres gráficos de barras para las tres diferentes regiones:

```{r}
# 10 conceptos más mencionados en Coquimbo
df_coq <- data_tf %>% filter(region == 'Coquimbo')

totales <- colSums(df_coq[,3:114])
temas <- colnames(df_coq)[3:114]

d <- data.frame(tema = temas,
                 total = totales)
conceptos_df <- d[order(d$total, decreasing=TRUE),]

coquimbo <- conceptos_df[1:10, c('tema', 'total')]


library(ggplot2)

ggplot(coquimbo) +
  geom_bar(aes(x = reorder(tema, total), y = total), stat='identity') +
  coord_flip() +
  ggtitle('Temas mas mencionados Coquimbo')
```

```{r}
# 10 conceptos más mencionados en Antofagasta

df_ant <- data_tf %>% filter(region == 'Antofagasta')

totales <- colSums(df_ant[,3:114])
temas <- colnames(df_ant)[3:114]

d <- data.frame(tema = temas,
                 total = totales)
conceptos_df <- d[order(d$total, decreasing=TRUE),]

antofagasta <- conceptos_df[1:10, c('tema', 'total')]


ggplot(antofagasta) +
  geom_bar(aes(x = reorder(tema, total), y = total), stat='identity') +
  coord_flip() +
  ggtitle('Temas mas mencionados Antofagasta')
```

```{r}
# 10 conceptos más mencionados en Metropolitana de Santiago

df_san <- data_tf %>% filter(region == 'Metropolitana de Santiago')

totales <- colSums(df_san[,3:114])
temas <- colnames(df_san)[3:114]

d <- data.frame(tema = temas,
                 total = totales)
conceptos_df <- d[order(d$total, decreasing=TRUE),]

santiago <- conceptos_df[1:10, c('tema', 'total')]


ggplot(santiago) +
  geom_bar(aes(x = reorder(tema, total), y = total), stat='identity') +
  coord_flip() +
  ggtitle('Temas mas mencionados Santiago')
```

6.  De la pregunta anterior, ¿considera que es razonable usar el conteo de frecuencias para determinar las regiones que tuvieron mayor participación en el proceso? ¿Por qué? Sugiera y solamente comente una forma distinta de hacerlo.

**Respuesta: El sumar la frecuencia de los temas mencionados por localidad no indica directamente la cantidad de gente que participó en el proceso, solo nos indica el numero de veces que fue discutido en los cabildos o en consulta individual. Al no saber el numero de gente que participo en estas reuniones la relacion de tema mencionado y partipacion ya no es directa.**

**Tambien esta el caso en que se hayan discutido muchos temas variados en vez de solamente uno en profundidad y/o varias veces. Es por eso que en la pregunta anterior decidimos crear un indice de participacion en el intento de reflejar estos dos escenarios, ponderando la cantidad de temas discutidos con la frecuencia en la que se discutieron. **
